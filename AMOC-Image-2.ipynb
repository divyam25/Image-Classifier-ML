{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gaurav\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "from sklearn.model_selection import GridSearchCV as gsc\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier as mlp\n",
    "import pickle\n",
    "from skimage import io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_data = 'E:\\\\CIFAR-10\\\\train'    #importing images CIFAR-10\n",
    "X = np.zeros((50000,3072))\n",
    "for i in range(1,50001) :\n",
    "    X[i-1]=pd.DataFrame(io.imread(os.path.join(path_data,str(i) + '.png')).flatten()).as_matrix().T\n",
    "    print (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(X,open(\"X.p\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X=pickle.load(open(\"X.p\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 3072)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.DataFrame.from_csv(\"E:\\\\CIFAR-10\\\\trainLabels.csv\")     #importing image labels CIFAR-10\n",
    "y = y.label.as_matrix()\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 92)   \n",
    "#Creating train and test flaps from imported data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bird'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[23972]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Creating KNN algorithm from scratch..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = np.zeros((200,40000))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(200) :                                           #KNN main logic (Euclidean distance metrics)\n",
    "    for j in range(0,40000) :\n",
    "        test[i][j]=np.sum((np.abs(X_test[i]-X_train[j])))\n",
    "    print (i)\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.empty((200,1),dtype=object)                         #training on the a subset of training data (200/50000) using KNN\n",
    "for i in range(200) :                                           #nearest_neighbour set to \"1\"\n",
    "    y_pred[i] = y_train[np.argmin(test[i])]\n",
    "    print (i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['bird'],\n",
       "       ['bird'],\n",
       "       ['bird'],\n",
       "       ['frog'],\n",
       "       ['truck'],\n",
       "       ['dog'],\n",
       "       ['airplane'],\n",
       "       ['airplane'],\n",
       "       ['deer'],\n",
       "       ['ship']], dtype=object)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = y_pred               #Predicted labels from KNN algorithm\n",
    "r[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['bird'],\n",
       "       ['cat'],\n",
       "       ['bird'],\n",
       "       ['bird'],\n",
       "       ['airplane'],\n",
       "       ['dog'],\n",
       "       ['airplane'],\n",
       "       ['airplane'],\n",
       "       ['horse'],\n",
       "       ['ship']], dtype=object)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d= pd.DataFrame(y_test[:200]).as_matrix()                 #the correct labels from the dataset used\n",
    "d[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41.5 % accuracy\n"
     ]
    }
   ],
   "source": [
    "counter = 0                               #Prediction Accuracy on the dataset\n",
    "for i in range(200) :\n",
    "    if(r[i] == d[i]) :\n",
    "        counter = counter + 1\n",
    "print (((counter/200) *100),\"%\",\"accuracy\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# The KNN algorithm developed from scratch gives an accuracy score of 41.5% over a small testing data size (200).... we didnt check for entire testing dataset as is it would take a minimum of 3 hours on the system we are working on. \n",
    "\n",
    "Applying KNN from scikit library for a probably more efficient prediction and lesser running time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=10, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cut the crap\n",
    "model_KNN = KNN(n_neighbors = 10)              #KNN template from scikit learn (nearest_neighbours = 10)\n",
    "model_KNN.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32550000000000001"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_KNN.score(X_test[:4000],y_test[:4000])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "With increasing testing dataset , prediction accuracy worsened (still better than logistic at the very least :P)\n",
    "Good thing is running time was 30 minutes for a testing data this long.\n",
    "Dimensionality reduction tweak coming up next.............zzzzzzzz "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_new = PCA(n_components = 10).fit_transform(X_train)     #Extracting important features... reducing 3000-D data to 10-D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_new = PCA(n_components = 10).fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=150, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_KNN = KNN(n_neighbors = 150,p=2)   #Fitting KNN after PCA\n",
    "model_KNN.fit(X_train_new,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3251"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_KNN.score(X_test_new,y_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Ok, So previously we calculated the model accuracy on a smaller dataset (only 4000 out of 10000) due to hungry computation times plus accuracy was anyhow going to be less(on the entire test data) than what was computed on smaller dataset. \n",
    "\n",
    "However after applying dimension reduction using Principle Component Analysis (PCA) which ultimately squeezed our 3000 dimensional data to merely a 10 dimensional data (with a big loss in information of course but reducing the running time now to a large extent), and also after hell lot of hyperparameter tuning, we could at least maintain the accuaracy of 0.32 over the \"entire\" dataset (if not increase it... ) which was otherwise not possible without dimension reductionality tweaks due to some obvious KNN mathematical proofs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Moving on to SVMs.......  (phew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Making a support vector machine (SVM) from scratch : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Warning: Following is a failed attempt to create a Support Vector Machine from scratch... \n",
    "#--------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_def = np.random.RandomState(7).rand(10,3072)\n",
    "func_svm = np.dot(X_train,theta_def.T)\n",
    "func_svm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#class labels for theta_def :\n",
    "labels = np.array([\"airplane\",\"automobile\",\"bird\",\"cat\",\"deer\",\"dog\",\"frog\",\"horse\",\"ship\",\"truck\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = np.zeros((40000,1))\n",
    "margins = np.zeros((40000,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n"
     ]
    }
   ],
   "source": [
    "for k in range(10) :\n",
    "    \n",
    "    func_svm = np.dot(X_train,theta_def.T)\n",
    "    for i in range(40000) :\n",
    "        label_temp = y_train[i]\n",
    "        index = np.asscalar(np.array(np.where(labels == label_temp)))\n",
    "        label_to_use = labels[index]\n",
    "        for j in range(10) :\n",
    "            if(j==index) :\n",
    "                margins[i][j] = 0\n",
    "            else :\n",
    "                margins[i][j] = max(0,func_svm[i][j] - func_svm[i][index] + 1)\n",
    "    for i in range(40000) :\n",
    "        loss[i] = np.sum(margins[i]) + 0.01 * np.sum(theta_def)\n",
    "    gradient = np.dot(X_train.T,loss) / 40000\n",
    "    for i in range(10) :\n",
    "        theta_def[i] = theta_def[i] - 0.00001 * gradient.T\n",
    "    print (k)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ nan,  nan,  nan, ...,  nan,  nan,  nan])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_def[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 9, ..., 9, 7, 9], dtype=int64)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = np.dot(a.T,X_test.T)\n",
    "pred_index = np.zeros((1,10000))\n",
    "pred_index = np.argmax(pred,axis=0)\n",
    "\n",
    "pred_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['airplane', 'airplane', 'truck', ..., 'truck', 'horse', 'truck'],\n",
       "      dtype='<U10')"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_withlabel = np.empty((1,10000),dtype=object)\n",
    "pred_withlabel = labels[pred_index]\n",
    "pred_withlabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['bird', 'cat', 'bird', ..., 'truck', 'bird', 'cat'], dtype=object)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.98 % accuracy\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for i in range(10000) :\n",
    "    if(y_test[i] == pred_withlabel[i]) :\n",
    "        counter = counter + 1\n",
    "print (((counter/10000) *100),\"%\",\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(40000) :\n",
    "    loss[i] = np.sum(margins[i]) + 0.01 * np.sum(theta_def ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3072, 1)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient = np.dot(X_train.T,loss) / 40000\n",
    "gradient.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(10) :\n",
    "    theta_def[i] = theta_def[i] - 0.000001 * gradient.T"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "Moving on to designing \"Neural Networks\" to classify images :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = mlp(verbose = 4,hidden_layer_sizes = (1500,700,300),random_state = 3)     #Added three layers into the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 8.73976734\n",
      "Iteration 2, loss = 2.49059977\n",
      "Iteration 3, loss = 2.03695433\n",
      "Iteration 4, loss = 1.93766967\n",
      "Iteration 5, loss = 1.85260972\n",
      "Iteration 6, loss = 1.78408608\n",
      "Iteration 7, loss = 1.71981863\n",
      "Iteration 8, loss = 1.67250883\n",
      "Iteration 9, loss = 1.65176742\n",
      "Iteration 10, loss = 1.64042694\n",
      "Iteration 11, loss = 1.59629855\n",
      "Iteration 12, loss = 1.58701364\n",
      "Iteration 13, loss = 1.57535417\n",
      "Iteration 14, loss = 1.54437968\n",
      "Iteration 15, loss = 1.54330947\n",
      "Iteration 16, loss = 1.56772843\n",
      "Iteration 17, loss = 1.55251440\n",
      "Iteration 18, loss = 1.54871945\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(1500, 700, 300), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=3, shuffle=True,\n",
       "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=4,\n",
       "       warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train,y_train)                        #Training the neural nets on the entire training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41880000000000001"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test,y_test)             #Neural Network model accuracy (yay!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\"Okay as we saw most of the \"traditional\" machine learning models applied here namely Logistic Regression, K-Nearest Neighbors (KNN), and Support Vector Machines(SVM) could hardly handle this data for sufficiently good predictions with the accuracy scores in the range of (24-35%).\n",
    "\n",
    "Where as on the other hand, the most sought model in use these days-Neural networks could give finally give us an accuracy score above 40%. We could have added more layers into the neural nets and increased the accuracy, but owing to our system limitation (GPU) it would definitely have taken large training time!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\"\"\"\"\"\"\"However nowadays \"Deep learning\" models are gaining quite a momentum for we can train the data using even larger layers and convolutions in much less time and much higher accuracy.\n",
    "\n",
    "Following is our hands-on on the Convolutional neural nets(CNN) to come up with a better acccuracy. We specially borrowed another system with a good GPU to let us compute deep CNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Switch to 3rd file ->"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
